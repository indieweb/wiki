https://indieweb.org/robots_txt

{{stub}}
'''<dfn>robots.txt</dfn>''' is a file used to inform web crawlers what parts of a site should or should not be crawled.

Example command names:
* [[user-agent|User-agent]]
* [[Disallow]]
* [[Noindex]]
* [[Allow]]

== Examples ==
See the following examples:
* http://pin13.net/robots.txt

== See Also ==
* [[robots]]
* http://www.robotstxt.org/robotstxt.html

https://indieweb.org/large_language_model

{{stub}}

A '''<dfn>large language model</dfn>''' is (AKA <dfn><abbr>LLM</abbr></dfn>) usually a reference to a service, like [[OpenAI]]’s ChatGPT, that synthesizes text based on a massive set of prose typically crawled and indexed from the open web and other sources and [[wikifying#Do_not_copy_from_LLM_generated_text|should not be used to contribute content to the IndieWeb wiki]]; several IndieWeb sites disclaim any use thereof for their content.

== Why ==
{{section-stub}}
=== Why disclaim ===
With more and more LLM-generated content being published to the web, e.g. by news outlets like Hoodline, people will increasingly look for actual human-written content instead, and disclaiming your use of LLMs will appeal to a larger and larger audience.

== How to ==
{{section-stub}}
=== How to block ===
* How to block LLM scrapers in [[11ty]]: 2024-04-15 [https://evilgeniuschronicles.org/posts/2024/04/15/blockin-bots-with-eleventy/ Blockin' Bots with Eleventy]

=== Tarpit & fighting back ===
* [https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/ AI haters build tarpits to trap and trick AI scrapers that ignore robots.txt]
* [https://petermolnar.net/article/anti-ai-nepenthes-fail2ban/index.html Example setup of an anti-AI tarpit on a self-hosted indieweb site]
* [[Cloudflare]] makes an effort to mitigate the effects of AI bots

=== Promote your work as human created ===
You can add a <dfn id="notbyai">[https://notbyai.fyi/ Not By AI]</dfn> badge on your website. See some [[#IndieWeb_Examples|IndieWeb Examples]] below.

== IndieWeb Examples ==
In rough date order of adding to personal sites:
=== Hidde ===
Hidde de Vries added a ‘no LLMs involved’ note to the site-wide footer of [https://hidde.blog hidde.blog] from 17 March 2023
<blockquote>No language models were involved in writing the blog posts on here.</blockquote>

=== capjamesg ===
{{capjamesg}} since at least 2023-07-14(?) added a "Not By AI" [[buttons#Related_efforts|image button]] on all his blog posts going back to [https://jamesg.blog/2020/08/30/adventures-on-the-indieweb/ at least 2020]

=== Aaron Parecki ===
{{aaronpk}} put a "Not by AI" badge in his global website footer (e.g. bottom of https://aaronparecki.com/) next to the IndieWeb/Microformats/Webmention [[buttons]] on 2023-10-15.

=== Tantek ===
{{t}} put a general disclaimer about no use of LLMs for his site on his homepage [https://tantek.com/2023/365/t2/no-large-language-model-llm-used on 2023-12-31]:
* https://tantek.com/#disclaimer <blockquote> No large language models were used in the production of this site. (inspired by RFC 9518 Appendix A ¶ 4) </blockquote>

=== Paul Watson ===
{{lazcorp}} put a general disclaimer about no use of LLMs for his site on his blog homepage  [https://www.lazaruscorporation.co.uk/blogs/artists-notebook] on 2024-01-04:
<blockquote>No large language models (LLM) or similar AI technologies were involved in writing the blog posts on here.</blockquote>
and also a similar statement and button (by https://notbyai.fyi/) on the footer of all pages on 2024-01-05.

=== Todd Presta ===
{{to2ds}} Updated the existing blurb above the fold on the homepage to use the term "LLMs" instead of the generic "AI." [https://toddpresta.com/#nollms] on 2024-01-05. Also added (Not BY AI) written and painted badges to the common footer along with the IndieWeb badge and link.

=== fluffy ===
{{beesbuzz.biz}} Added a blurb to [https://beesbuzz.biz/about#ai their about page] on 2025-07-23.

=== Matt Lee ===
{{mat.tl}} blocks as much of this as possible. His content is not permitted to be used to train such things. 

His [[Libre.fm]] and [[1800www.com]] projects are changing their mission/focus as result. 

=== ... add yourself ... ===
{{addyourself}}

== IndieWeb Wiki Examples ==
Do not use LLMs for content for the wiki: 
* in defintions: [[definition#Do_not_copy_from_LLM_generated_text]]
* or content in general: [[wikifying#Do_not_copy_from_LLM_generated_text]]

Don't even think about using ChatGPT to contribute material to the wiki, because you don't have the ability to know you can contribute it to the public domain / CC0.
* 2024-01-08 The Guardian UK: [https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai ‘Impossible’ to create AI tools like ChatGPT without copyrighted material, OpenAI says] <br/>

== Other Examples ==
* IETF example: https://www.rfc-editor.org/rfc/rfc9518.html#appendix-A-4 <blockquote>No large language models were used in the production of this document.</blockquote>
* https://notbyai.fyi/

== IndieWeb opinions ==
* 2023-03-13 {{t}}: [https://tantek.com/2023/072/t1/blog-as-if-ai-trained-posts Blog as if there’s an #AI being trained to be you based on your blog posts.]
* {{addyourself}}

== Other Examples ==
{{section-stub}}
* News publication example: https://www.sfchronicle.com/ai_use/
* ...

== Criticism ==
=== Hammering bandwidth while disrespecting robots.txt ===
* 2025-04-15 [https://adactio.com/journal/21831 Denial]
<blockquote>The worst of the internet is continuously attacking the best of the internet. This is a distributed denial of service attack on the good parts of the World Wide Web.</blockquote>
* 2025-03-17 [https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html Please stop externalizing your costs directly into my face]
<blockquote>Over the past few months, instead of working on our priorities at SourceHut, I have spent anywhere from 20-100% of my time in any given week mitigating hyper-aggressive LLM crawlers at scale. [...] If you think these crawlers respect robots.txt then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, robots.txt be damned.</blockquote>
* 2024-06-15 [https://rknight.me/blog/perplexity-ai-is-lying-about-its-user-agent/ Perplexity AI Is Lying about Their User Agent]

=== Encourages disregarding copyright ===
* https://t.co/1rmFNq7spR short link to 2024-04-06 NYT: [https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html How Tech Giants Cut Corners to Harvest Data for A.I.] / OpenAI, Google and Meta ignored corporate policies, altered their own rules and discussed skirting copyright law as they sought online information to train their newest artificial intelligence systems.
* 2024-04-30 NYTimes: [https://www.nytimes.com/2024/04/30/business/media/newspapers-sued-microsoft-openai.html 8 Daily Newspapers Sue OpenAI and Microsoft Over A.I.] / The suit, which accuses the tech companies of copyright infringement, adds to the fight over the online data used to power artificial intelligence.

=== Encourages training on private data ===
* https://twitter.com/heyitsseher/status/1776823362292969880 <blockquote>Google quietly changed policies to scrape public Google Doc data to train AI.<br /><br />Then purposely released new terms of service on "Fourth of July weekend, when people were typically focused on the holiday"<br /><br />How Tech Giants Cut Corners to Harvest Data for A.I. https://t.co/1rmFNq7spR</blockquote>

=== Discourages open creativity and sharing ===
* 2024-03-11 {{lmorchard}}: [https://blog.lmorchard.com/2024/03/11/dance-for-the-bots/ Dance like the bots aren't watching?] / TL;DR: Why bother sharing anything on the open web if it's just going to be fodder for extractive, non-reciprocal bots?

* 2024-04-22 The Atlantic: [https://www.theatlantic.com/technology/archive/2024/04/generative-ai-search-llmo/678154/ It’s the End of the Web as We Know It] <blockquote>SEO will morph into LLMO: large-language-model optimization, the incipient industry of manipulating AI-generated material to serve clients’ interests. <br/>[...]<br/>LLMs aren’t people we connect with. Eventually, people may stop writing, stop filming, stop composing—at least for the open, public web.</blockquote>

=== Abused to waste developer time ===
Criticism: LLMs used to waste developer time with fake security bounty bug reports:
* (from the maintainer of [[curl]]) 2024-01-02 [https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/ The I in LLM stands for intelligence] <blockquote>Like for the email spammers, the cost of this ends up in the receiving end. The ease of use and wide access to powerful LLMs is just too tempting. I strongly suspect we will get more LLM generated rubbish in our Hackerone inboxes going forward.</blockquote>

=== Fails basic context dependence ===
Can fail basic context-dependence, like examples vs commands: 
* 2024-06-06 [https://simonwillison.net/2024/Jun/6/accidental-prompt-injection/ Accidental prompt injection against RAG applications]

=== Scraping for training widely rejected ===
85% of Cloudflare's customers prefer to block GenAI training scrapers: 
* 2024-07-03 [https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click Declare your AIndependence: block AI bots, scrapers and crawlers with a single click]

=== Allows the creation of abusive content for deliberate  harm ===
* 2025-05-22 [https://www.zhangjingna.com/blog/2025/5/22/someone-released-an-ai-model-that-makes-deepfakes-of-me-without-my-consent Someone released an AI model that makes deepfakes of me, without my consent] by Jingna Zhang

=== Risk of misleading or hazardous output ===
* 2025-05-07 [https://osteophage.neocities.org/projects/machine-generated-hall-of-shame Machine-Generated Garbage Hall of Shame]

=== Other Criticism ===
* {{citation
| title = Anthropic’s new AI model turns to blackmail when engineers try to take it offline
| url = https://techcrunch.com/2025/05/22/anthropics-new-ai-model-turns-to-blackmail-when-engineers-try-to-take-it-offline/
| author = [https://techcrunch.com/author/maxwell-zeff/ Maxwell Zeff]
| published = 2025-05-22
| archiveurl = https://web.archive.org/web/20250611190000/https://techcrunch.com/2025/06/11/at-wwdc-apple-says-it-will-use-ai-to-tag-apps-to-improve-discoverability-on-the-app-store/?sidebar=a
}}

* {{citation
| title = Comedian John Mulaney brutally roasts SF techies at Dreamforce
| url = https://sfstandard.com/2024/09/19/comedian-john-mulaney-brutally-roasts-sf-techies-and-ai-at-dreamforce/
| author = [https://sfstandard.com/author/kevin-v-nguyen/ Kevin V Nguyen]
| published = 2024-09-19
| archiveurl = https://web.archive.org/web/20250611193926/https://sfstandard.com/2024/09/19/comedian-john-mulaney-brutally-roasts-sf-techies-and-ai-at-dreamforce/
}}
<blockquote>“Let me get this straight,” John Mulaney said. “You’re hosting a ‘future of AI’ event in a city that has failed humanity so miserably?”

He added, “Can AI sit there in a fleece vest? Can AI not go to events and spend all day at a bar?”
</blockquote>

* Don't write fan letters using GenAI, unlike what the [[Google Gemini]] ad is encouraging you to do:
** {{citation
| title = Dear Google, who wants an AI-written fan letter?
| url = https://techcrunch.com/2024/07/28/dear-google-who-wants-an-ai-written-fan-letter/
| author = [https://techcrunch.com/author/anthony-ha/ Anthony Ha]
| published = 2024-07-28
| archiveurl = https://web.archive.org/web/20250611194641/https://techcrunch.com/2025/06/11/can-scale-ai-and-alexandr-wang-reignite-metas-ai-efforts/?sidebar=a
}}

* {{citation
| title = Google’s Olympics ad went viral for all the wrong reasons
| url = https://www.cnn.com/2024/07/29/tech/googles-ai-olympics-ad-backlash/index.html
| author = [https://www.cnn.com/profiles/clare-duffy Clare Duffy]
| published = 2024-07-29
| archiveurl = http://web.archive.org/web/20240731125757/https://www.cnn.com/2024/07/29/tech/googles-ai-olympics-ad-backlash/index.html
}}

* 2025: {{adactio}} had to turn off the tags feature on [[Huffduffer]] due to AI scraping ([[Huffduffer#Issues|more info]])

== See Also ==
* https://en.wikipedia.org/wiki/Large_language_model
* [[ai;dr]]
* https://github.com/ai-robots-txt/ai.robots.txt
* How to turn off training Grok on your tweets: uncheck this setting: https://twitter.com/settings/grok_settings
* [[autocorrect]]
* 2022-11-13 comic: [https://marketoonist.com/2022/11/by-bots-for-bots.html By Bots, For Bots] https://marketoonist.com/wp-content/uploads/2022/11/221114.n.bots_.jpg
* 2024-09-20 {{t}}: [https://tantek.com/2024/264/t1/cc-nt-for-no-training-llm-genai Can we have CC-NT licenses for no-training (ML/LLM, GenAI in general), just like we have CC-NC for non-commercial?]
* https://www.aitrainingstatement.org/
* "I’m intrigued and bored at the same time: I find it quickly becomes quite tedious. I have a sort of inner dissatisfaction when I play with it, a little like the feeling I get from eating a lot of confectionery when I’m hungry. I suspect this is because the joy of art isn’t only the pleasure of an end result but also the experience of going through the process of having made it." [https://www.bostonreview.net/forum_response/ais-walking-dog/ AI’s Walking Dog] by Brian Eno
* [[ai.txt]]
* blog about GenAI / LLM related failures and/or organizations seemingly doing silly things with such technologies: https://pivot-to-ai.com/
* [https://darkvisitors.com/agents List of LLM bot user agents]
* Criticism of use of (and assumptions around use of) LLMs in work tasks, and especially to "replace" humans: https://www.rawsignal.ca/newsletter-archive/none-of-this-is-real-and-it-doesnt-matter/
** "Photo by max laurell.<br>							<br>				<br>We have officially entered the tree-falling-in-forest-era of white-collar work. Our friend who is a big dude in fundraising just declared the end of the pitch deck. He pointed to decks that were auto-generated and then auto-summarized. And asserted that if no one is writing it and no one is reading it, there’s just no point at all in having that piece of collateral.<br><br><br><br>Over here in management-training land, our bosses are so busy reading the summaries of all the meetings they didn’t attend, there’s no time for anything else on their calendars. They ask to send notetakers to management training in their stead. Or get a summary of what they missed. We get it. Genuinely, there’s more to do than there are hours in the day.<br><br><br><br>The problem is that the summary approach falls way down on implementation. Leadership transformation nerds will tell you there is no growth or development without reflection. So if we send you a summary of management training that says: Reflect on how you’re showing up as a leader and where the tools you are deploying are in service of you, your team, your org. And where they are not. You can read the summary meant to prompt reflection but that is not the same as doing any actual reflecting.<br><br><br><br>Faster, sure. But comically ineffective for the stated task.<br><br><br><br>The comedy era of automation. Where an entire meeting is attended by notetakers but no participants. And if you’re quick to point out that surely, of all meetings, this meeting could have been an email. Take a beat and pull it all the way through. Too busy to write that email? Just generate it instead. And if you’re too busy to read any of your email? Well, there’s a tool for that, too. Here at the bottom, we find ourselves back at the top. What is the point of auto-generating only to auto-summarize?<br><br><br><br>Recursive malfunction<br><br><br><br>It’s ok to want to be productive at work. It’s even cool to work on a thing you care about and want to see happen in the world. And it’s not a problem to use tools in the course of your work. But there’s a point where we tip from productivity gains into losses. More notes from more meetings that no one attends does not make us a more productive workforce. More emails that no one reads doesn’t mean more alignment or shared context or a smarter workforce.<br><br><br><br>This is silliness. This is the output of work without any of the inputs. This is sound. And fury.<br><br><br><br>And there’s no fucking point to any of it.<br><br><br><br>We’ve all worked with someone, usually a junior person. Often an intern. First to sign on in the morning. Last to clock out at the end of the day. And, when pressed about how they spent their time, they attended a lot of meetings. Read all of the emails in their inbox. Caught up on slack. And that was about it.<br><br><br><br>No one, not a single manager who has been at it for more than 10 minutes, points to that person as the most productive member of the team. An invaluable contributor. If you’re being generous, you say that person is coming up to speed. That they’re learning. And at some point, you pull them aside and talk about the difference between the theater of work and actual work.<br><br><br><br>Because the wonderful part about goals and objectives and even mission statements is that we know what we’re trying to get done. No organization has a quarterly goal around sending more email (maybe Mailchimp does). Or sitting in the most meetings (maybe Zoom does). But unless it’s your core business, those are tools you use to achieve the thing, not the thing itself.<br><br><br><br>This is the dream<br><br><br><br>The people pitching all this will totally acknowledge that the current version is ridiculous. Well. Not all of them. Some of them are so heartbreakingly earnest about their blog-slop, or design-slop, or pitchdeck-slop, and can’t understand why you’re not impressed. Those ones seem to have a lot of time to post on LinkedIn.<br><br><br><br>But like, many of them, the more polished ones, can admit that this is all still sort of silly. For those folks, the nonsense is an intermediate stage. Sure, having bots attend each other’s meetings is silly, but it doesn’t really matter, and it’s on the way to eliminating the need for meetings altogether. And yes, the bots aren’t doing a very good job at creative output yet, but, you know…for now we’ll have the humans come in and clean up the mess. And in 3-5 years we probably won’t need the humans at all. At least, this is the dream.<br><br><br><br>That dream is rooted in a worldview. It’s a worldview we should talk about because it’s not only the root of the slop showing up in your feeds, but it’s also the root of the pressure to make your work into slop. The people who hold this worldview have been working hard to distribute and accelerate it. When Eric Schmidt talks about the “San Francisco Consensus,” it sounds like he’s talking about a set of AI predictions, but it’s clear he’s also talking about this.<br><br><br><br>We’ve never seen them crisply articulate it, we don’t get invited to their group chats, but empirically it’s roughly:<br><br><br><br>Companies exist to make money, and the most money goes to people who can find leverage — maximum impact per unit cost.<br><br><br><br>Humans are a major cost.<br><br><br><br>Most employees are over-entitled and under-accountable and have an inflated sense of their own worth. This is particularly true for people in creative fields — writing, design, art direction — or those with a background in humanities.<br><br><br><br>Most work is also bullshit. Especially communication and coordination work — meetings, presentations, management conversations. Those things keep people from doing their real work, by which we generally mean lone genius individual contribution.<br><br><br><br>Automating away the bullshit work is righteous because that work has no value.<br><br><br><br>Automating away the humans is righteous because it will reduce the dependence on entitled employees, and produce an appropriate level of fear/obedience in the ones who remain.<br><br><br><br>The coolest thing in the world would be to build a billion-dollar company as a single person running an army of AI bots.<br>The major LLM vendors don’t say these things, but it’s implicit in a lot of how they talk about their offerings. No sensible leader would pay earth dollars for a bot that transcribes silent meetings with other bots, or tells you how much house paint to add to your chocolate chip cookies. But when those companies sell the promise of saving on payroll costs, people are buying the dream. When new benchmarks drop showing which human certification tests the chatbots can now pass, what human work they can now sort of do, people are buying.<br><br><br><br>If you’re bought into the worldview above, this is the dream.<br><br><br><br>This is a nightmare<br><br><br><br>If this is the dream, we don’t want it.<br><br><br><br>Like so much LLM output it’s not even very creative, just derivative and beige and vaguely unsettling. There’s nothing here that isn’t age-old grievances of business owners about their employees, dressed up in some scraps of poorly understood organizational psychology and modern finance. They aren’t re-inventing work, they’re re-inventing shit work. Because this? None of this is how great work happens.<br><br><br><br>Remember great work? Genuinely great, thriving team, trusting each other, flow-state, catching the pass, you make me better and I make you better, holy shit I can’t believe we pulled that off, years later the people from that team are out in the world doing amazing things and making each other proud? Remember great fucking work?<br><br><br><br>You don’t get that by removing the humanity, or the humans. It’s hard work to run a team or an organization well, we know, but the temptation to reach for some quick fix at the expense of your people never works out. If your teams are underperforming, there are concrete steps you can take. If you have an accountability problem, fix your management. The solution to your shit meetings is to run better ones. These are all skills you can build, but you won’t get them by skipping the hard parts and skimming a summary.<br><br><br><br>Building a billion-dollar company alone with your bots is not the coolest thing in the world. It’s honestly a pretty sad and lonely image, and relies on a massive amount of damage along the way to make it possible. But building something enduring, something with real impact in the world, alongside a team of folks you trust and believe in, and who trust and believe in you, and bringing out the best in each other? Yeah, that’s the dream.<br><br><br><br>— Melissa & Johnathan<br>		<br>Upcoming Programs<br><br><br><br>Actually good, actually useful training <br><br><br><br><br>	<br>							Online<br>						Oct 9-Nov 13<br>		<br><br>		BPX Fall	<br>			Register now"

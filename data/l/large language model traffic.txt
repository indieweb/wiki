https://indieweb.org/large_language_model_traffic

{{stub}}

[[large language model|Large language models]] traffic refers to web requests made by LLM operators, which may be used to crawl data for use in training AI models, or to answer a user's query in a "search" mode (i.e. ChatGPT Search).

Increasing usage of LLM tools corresponds with increased [[crawler]] traffic from web [[robot|robots]]. [[website]] owners have noticed spikes in traffic which have made some public sites unavailable. Some crawlers appear not to respect [[robots txt|robots.txt]] directives.

== IndieWeb Examples ==

Several members of the IndieWeb community have reported AI traffic becoming an increasing burden on their servers.

* {{artlung}} was told by system administrators from his [[hosting|web host]] that bot spikes accounted for multiple crashes of Apache.

* ''...add yourself''

== News reporting ==
{{section stub}}


== Traffic reports ==
{{section stub}}

== Tools to combat ==
{{section stub}}

* [https://github.com/TecharoHQ/anubis Anubis] is a "Web AI Firewall Utility". The "[https://anubis.techaro.lol/docs/design/how-anubis-works How Anubis works]" documentation says that Anubis "uses a proof-of-work challenge to ensure that clients are using a modern browser and are able to calculate SHA-256 checksums".
** [https://social.anoxinon.de/@Codeberg/115033796075422170 Codeberg reported that at least one AI crawler was capable of bypassing Anubis],:
<blockquote>However, we can confirm that at least Huawei networks now send the challenge responses and they actually do seem to take a few seconds to actually compute the answers. It looks plausible, so we assume that AI crawlers leveled up their computing power to emulate more of real  browser behaviour to bypass the diversity of challenges that platform enabled to avoid the bot army.</blockquote>
* [[Cloudflare]] has a feature called [https://developers.cloudflare.com/bots/additional-configurations/block-ai-bots/ Block AI Bots] which you can use to block AI bots.

== See also ==
* [[large language model]]

== See Also ==

* [[robots_txt|robots.txt]]
* [https://darkvisitors.com/agents Dark Visitors keeps a list of robot user agents]. This includes AI bots which are listed in categories like "AI Agent", "AI Assistant", "AI Data Scrapers" and more general bots like "Archivers" and link preview "Fetchers".

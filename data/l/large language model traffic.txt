https://indieweb.org/large_language_model_traffic

{{stub}}

'''<dfn>[[large language model|Large language model]] traffic</dfn>''' refers to web requests made by LLM operators to ingest data for use in training AI models, or to answer user queries in "search" mode (i.e. ChatGPT Search).

Increasing usage of LLM tools corresponds with increased [[crawler]] traffic from web [[robot|robots]]. [[website]] owners have noticed spikes in traffic which have made some public sites unavailable. Some crawlers appear not to respect [[robots txt|robots.txt]] directives.

== IndieWeb Examples ==

Several members of the IndieWeb community have reported AI traffic becoming an increasing burden on their servers.

* {{artlung}} was told by system administrators from his [[hosting|web host]] that bot spikes accounted for multiple crashes of Apache.
* As a result of heavy traffic on the indieweb.org wiki, web server nginx rules were added to prevent access to "diff" pages for individual wiki pages for not-logged in user agents
* {{capjamesg}} prefers AI bots not to crawl his website. Because of accounts that some AI bots do not adhere to robots.txt (i.e. https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/), James blocks many AI bot user agents using nginx. Matching user agents are returned a 404 for every web page.
* [[User:Jak2k.eu|Jak2k]] does not want AI bots to crawl his website. He used [https://anubis.techaro.lol/ Anubis] in the past, but switched to [https://iocaine.madhouse-project.org/ Iocaine] because it does not require client-side JavaScript and can also poison AIs.

* {{addyourself}}

== News reporting ==
<!-- recommend using https://indieweb.org/Template:citation when adding new articles, including an archive URL -->
* {{citation
| title = We’re Walling Off The Open Internet To Stop AI—And It May End Up Breaking Everything Else
| url = https://www.techdirt.com/2025/09/08/were-walling-off-the-open-internet-to-stop-ai-and-it-may-end-up-breaking-everything-else/
| author = [https://www.techdirt.com/user/mmasnick/ Mike Masnick]
| published = 2025-09-08
| archiveurl = http://web.archive.org/web/20250919005945/https://www.techdirt.com/2025/09/08/were-walling-off-the-open-internet-to-stop-ai-and-it-may-end-up-breaking-everything-else/
}}
* {{citation
| title = The Open-Source Software Saving the Internet From AI Bot Scrapers
| url = https://www.404media.co/the-open-source-software-saving-the-internet-from-ai-bot-scrapers/
| author = [https://www.404media.co/author/emanuel-maiberg/ Emanuel Maiberg]
| published = 2025-07-07
| archiveurl = https://web.archive.org/web/20250827212038/https://www.404media.co/the-open-source-software-saving-the-internet-from-ai-bot-scrapers/
}}
* {{citation
| title = AI bots strain Wikimedia as bandwidth surges 50%
| url = https://arstechnica.com/information-technology/2025/04/ai-bots-strain-wikimedia-as-bandwidth-surges-50/
| author = [https://arstechnica.com/author/benjedwards/ Benj Edwards]
| published = 2025-04-02
| archiveurl = https://web.archive.org/web/20250819214210/https://arstechnica.com/information-technology/2025/04/ai-bots-strain-wikimedia-as-bandwidth-surges-50/
}}
* {{citation
| title = Open source devs say AI crawlers dominate traffic, forcing blocks on entire countries
| url = https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/
| author = [https://arstechnica.com/author/benjedwards/ Benj Edwards]
| published = 2025-03-25
| archiveurl = http://web.archive.org/web/20250916022653/https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/
}}
* {{citation
| title = Cloudflare turns AI against itself with endless maze of irrelevant facts
| url = https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/
| author = [https://arstechnica.com/author/benjedwards/ Benj Edwards]
| published = 2025-03-21
| archiveurl = https://web.archive.org/web/20250327162626/https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/
}}

* {{citation
| title = Are AI Bots Knocking Digital Collections Offline? An Interview with Michael Weinberg
| url = https://scholarlykitchen.sspnet.org/2025/06/23/are-ai-bots-knocking-digital-collections-offline/
| author = [https://scholarlykitchen.sspnet.org/author/lisa-janicke-hinchliffe/ Lisa Janicke Hinchliffe]
| published = 2025-06-23
| archiveurl = http://web.archive.org/web/20250717051935/https://scholarlykitchen.sspnet.org/2025/06/23/are-ai-bots-knocking-digital-collections-offline/
}}
* {{citation
| title = AI Has Created a Battle Over Web Crawling: Training data may wind up in short supply as websites restrict crawler bots
| url = https://spectrum.ieee.org/web-crawling
| author = [https://spectrum.ieee.org/u/eliza-strickland Eliza Strickland]
| published = 2024-08-31
| archiveurl = http://web.archive.org/web/20250912070229/https://spectrum.ieee.org/web-crawling
}}

== Traffic reports ==
* 2025-09-10 [https://flowingdata.com/2025/09/10/bots-account-for-almost-a-third-of-web-traffic/ Bots account for almost a third of web traffic] (summary of [[Cloudflare]] data)
* 2025-09-08 ''[https://tollbit.com/bots/25q2/ AI Scraping Is On The Rise]'' ([https://tollbit.com/ TollBit] State of the Bots - Q2 2025)
* {{citation
| title = 
New Fastly Threat Research Reveals AI crawlers make up almost 80% of AI bot traffic, Meta Leads AI Crawling As ChatGPT Dominates Real-Time Web Traffic
| url = https://www.fastly.com/press/press-releases/new-fastly-threat-research-reveals-ai-crawlers-make-up-almost-80-of-ai-bot
| published = 2025-08-19
| archiveurl = https://web.archive.org/web/20250822232826/https://www.fastly.com/press/press-releases/new-fastly-threat-research-reveals-ai-crawlers-make-up-almost-80-of-ai-bot
}}
* 2025-07-21 [https://www.libraryjournal.com/story/ai-bots-swarm-library-cultural-heritage-sites-causing-slowdowns-and-crashes AI Bots Swarm Library, Cultural Heritage Sites, Causing Slowdowns and Crashes]
* [https://library.duke.edu/using/off-campus/impact-of-bots Impact of AI Bots on Library Websites] (Duke University) ''The overwhelming number of simultaneous requests that these AI bots make on our websites has sometimes rendered them inaccessible to our human library patrons.''
* 2025-04-01 [https://diff.wikimedia.org/2025/04/01/how-crawlers-impact-the-operations-of-the-wikimedia-projects/ How crawlers impact the operations of the Wikimedia projects] ''We are observing a significant increase in request volume, with most of this traffic being driven by scraping bots collecting training data for large language models (LLMs) and other use cases.''
* 2025-04-23 [https://www.inmotionhosting.com/blog/ai-crawlers-slowing-down-your-website/ Why AI Crawlers Are Slowing Down Your Website: The Case for Dedicated Hosting Solutions]

== Tools to combat ==
{{section-stub}}

* [https://github.com/TecharoHQ/anubis Anubis] is a "Web AI Firewall Utility". The "[https://anubis.techaro.lol/docs/design/how-anubis-works How Anubis works]" documentation says that Anubis "uses a proof-of-work challenge to ensure that clients are using a modern browser and are able to calculate SHA-256 checksums".
** [https://social.anoxinon.de/@Codeberg/115033796075422170 Codeberg reported that at least one AI crawler was capable of bypassing Anubis],:
<blockquote>…we can confirm that at least Huawei networks now send the challenge responses and they actually do seem to take a few seconds to actually compute the answers… we assume that AI crawlers leveled up their computing power to emulate more of real browser behaviour </blockquote>
** Anubis can be configured to work without [[JavaScript]] using <code>[https://anubis.techaro.lol/docs/admin/configuration/challenges/metarefresh/ challenge.algorithm.metarefresh]</code>
* [[Cloudflare]] has a feature called [https://developers.cloudflare.com/bots/additional-configurations/block-ai-bots/ Block AI Bots] which you can use to block AI bots.
* [[fail2ban]] bans logins from IP addresses that show signs of malicious activity
* [https://iocaine.madhouse-project.org/ Iocaine] is simiar to Anubis, but uses scriptable bot recognition on the server only and responds with garbage text to recognized bots with the goal of poisoning AIs.
* [https://github.com/ai-robots-txt/ai.robots.txt ai.robots.txt] lists user agents and their sources to help write [[server|web server]] blocking rules such as in [[htaccess]] rules

== Proposed Tools ==
* [https://blog.cloudflare.com/introducing-pay-per-crawl/ Introducing pay per crawl: Enabling content owners to charge AI crawlers for access]
* [https://rslstandard.org RSL: Really Simple Licensing] ''RSL is an open standard that lets publishers define machine-readable licensing terms for their content, including attribution, pay per crawl, and pay per inference compensation.''
* [https://contentsignals.org Content-Signals], from [[Cloudflare]] proposes an [[HTTP header]] called <code>Content-Signal</code> with values of <code>ai-train</code>, <code>search</code>, <code>ai-input</code> with values of <code>yes</code> or <code>no</code> to steer bots and scrapers, should they respect the header.

== Brainstorming ==

=== Types of LLM bot ===

There are several types of bot that act on behalf of or collect data for an LLM. The types of bot vary by service provider, but are mainly distinguished by their intent.

Some bots crawl content (crawlers); others retrieve content for use in answering a user's query ("search bots" or bots that retrieve a web page in service of answering a user's question); others download data for the purpose of training AI models.

Security firm [https://datadome.co/ DataDome] distinguishes 3 types:
* ''<b>Training scrapers</b>, which ingest large volumes of public content to improve model performance. These are typically used to build or refine foundation models and may not honor robots.txt or rate limits.''
* ''<b>Prompt-time fetchers</b>, which retrieve real-time data to supplement LLM outputs—think of AI copilots or search assistants querying web pages on-the-fly to answer user prompts.''
* ''<b>Agentic crawlers</b>, which act more like users. These bots are capable of clicking, scrolling, submitting forms, and navigating complex UIs, often as part of a RAG (retrieval-augmented generation) pipeline or testing framework.''
Source: ''[https://datadome.co/threat-research/ai-agents-llm-crawlers/ AI Agents at the Gate: Understanding & Securing Against LLM Crawlers]''

== See Also ==
* [[large language model]]
* [[robots_txt|robots.txt]]
* [https://darkvisitors.com/agents Dark Visitors keeps a list of robot user agents]. This includes AI bots which are listed in categories like "AI Agent", "AI Assistant", "AI Data Scrapers" and more general bots like "Archivers" and link preview "Fetchers".
* [[common crawl]] is intended to share site data with crawlers so they would avoid inflicting onerous web traffic
* [[large language model]]

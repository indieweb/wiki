https://indieweb.org/large_language_model_traffic

{{stub}}

'''<dfn>[[large language model|Large language models]] traffic</dfn>''' refers to web requests made by LLM operators, which may be used to crawl data for use in training AI models, or to answer a user's query in a "search" mode (i.e. ChatGPT Search).

Increasing usage of LLM tools corresponds with increased [[crawler]] traffic from web [[robot|robots]]. [[website]] owners have noticed spikes in traffic which have made some public sites unavailable. Some crawlers appear not to respect [[robots txt|robots.txt]] directives.

== IndieWeb Examples ==

Several members of the IndieWeb community have reported AI traffic becoming an increasing burden on their servers.

* {{artlung}} was told by system administrators from his [[hosting|web host]] that bot spikes accounted for multiple crashes of Apache.
* As a result of heavy traffic on the indieweb.org wiki, web server nginx rules were added to prevent access to "diff" pages for individual wiki pages for not-logged in user agents
* {{capjamesg}} prefers AI bots not to crawl his website. Because of accounts that some AI bots do not adhere to robots.txt (i.e. https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/), James blocks many AI bot user agents using nginx. Matching user agents are returned a 404 for every web page.

* {{addyourself}}

== News reporting ==
<!-- recommend using https://indieweb.org/Template:citation when adding new articles, including an archive URL -->
* {{citation
| title = We’re Walling Off The Open Internet To Stop AI—And It May End Up Breaking Everything Else
| url = https://www.techdirt.com/2025/09/08/were-walling-off-the-open-internet-to-stop-ai-and-it-may-end-up-breaking-everything-else/
| author = [https://www.techdirt.com/user/mmasnick/ Mike Masnick]
| published = 2025-09-08
| archiveurl = http://web.archive.org/web/20250919005945/https://www.techdirt.com/2025/09/08/were-walling-off-the-open-internet-to-stop-ai-and-it-may-end-up-breaking-everything-else/
}}
* {{citation
| title = The Open-Source Software Saving the Internet From AI Bot Scrapers
| url = https://www.404media.co/the-open-source-software-saving-the-internet-from-ai-bot-scrapers/
| author = [https://www.404media.co/author/emanuel-maiberg/ Emanuel Maiberg]
| published = 2025-07-07
| archiveurl = https://web.archive.org/web/20250827212038/https://www.404media.co/the-open-source-software-saving-the-internet-from-ai-bot-scrapers/
}}
* {{citation
| title = AI bots strain Wikimedia as bandwidth surges 50%
| url = https://arstechnica.com/information-technology/2025/04/ai-bots-strain-wikimedia-as-bandwidth-surges-50/
| author = [https://arstechnica.com/author/benjedwards/ Benj Edwards]
| published = 2025-04-02
| archiveurl = https://web.archive.org/web/20250819214210/https://arstechnica.com/information-technology/2025/04/ai-bots-strain-wikimedia-as-bandwidth-surges-50/
}}
* {{citation
| title = Open source devs say AI crawlers dominate traffic, forcing blocks on entire countries
| url = https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/
| author = [https://arstechnica.com/author/benjedwards/ Benj Edwards]
| published = 2025-03-25
| archiveurl = http://web.archive.org/web/20250916022653/https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/
}}
* {{citation
| title = Are AI Bots Knocking Digital Collections Offline? An Interview with Michael Weinberg
| url = https://scholarlykitchen.sspnet.org/2025/06/23/are-ai-bots-knocking-digital-collections-offline/
| author = [https://scholarlykitchen.sspnet.org/author/lisa-janicke-hinchliffe/ Lisa Janicke Hinchliffe]
| published = 2025-06-23
| archiveurl = http://web.archive.org/web/20250717051935/https://scholarlykitchen.sspnet.org/2025/06/23/are-ai-bots-knocking-digital-collections-offline/
}}
* {{citation
| title = AI Has Created a Battle Over Web Crawling: Training data may wind up in short supply as websites restrict crawler bots
| url = https://spectrum.ieee.org/web-crawling
| author = [https://spectrum.ieee.org/u/eliza-strickland Eliza Strickland]
| published = 2024-08-31
| archiveurl = http://web.archive.org/web/20250912070229/https://spectrum.ieee.org/web-crawling
}}

== Traffic reports ==
{{section-stub}}
* 2025-09-10 [https://flowingdata.com/2025/09/10/bots-account-for-almost-a-third-of-web-traffic/ Bots account for almost a third of web traffic] (summary of [[Cloudflare]] data)
* {{citation
| title = 
New Fastly Threat Research Reveals AI crawlers make up almost 80% of AI bot traffic, Meta Leads AI Crawling As ChatGPT Dominates Real-Time Web Traffic
| url = https://www.fastly.com/press/press-releases/new-fastly-threat-research-reveals-ai-crawlers-make-up-almost-80-of-ai-bot
| published = 2025-08-19
| archiveurl = https://web.archive.org/web/20250822232826/https://www.fastly.com/press/press-releases/new-fastly-threat-research-reveals-ai-crawlers-make-up-almost-80-of-ai-bot
}}
* 2025-07-21 [https://www.libraryjournal.com/story/ai-bots-swarm-library-cultural-heritage-sites-causing-slowdowns-and-crashes AI Bots Swarm Library, Cultural Heritage Sites, Causing Slowdowns and Crashes]
* [https://library.duke.edu/using/off-campus/impact-of-bots Impact of AI Bots on Library Websites] (Duke University) ''The overwhelming number of simultaneous requests that these AI bots make on our websites has sometimes rendered them inaccessible to our human library patrons.''
* 2025-04-01 [https://diff.wikimedia.org/2025/04/01/how-crawlers-impact-the-operations-of-the-wikimedia-projects/ How crawlers impact the operations of the Wikimedia projects] ''We are observing a significant increase in request volume, with most of this traffic being driven by scraping bots collecting training data for large language models (LLMs) and other use cases.''
* 2025-04-23 [https://www.inmotionhosting.com/blog/ai-crawlers-slowing-down-your-website/ Why AI Crawlers Are Slowing Down Your Website: The Case for Dedicated Hosting Solutions]

== Tools to combat ==
{{section-stub}}

* [https://github.com/TecharoHQ/anubis Anubis] is a "Web AI Firewall Utility". The "[https://anubis.techaro.lol/docs/design/how-anubis-works How Anubis works]" documentation says that Anubis "uses a proof-of-work challenge to ensure that clients are using a modern browser and are able to calculate SHA-256 checksums".
** [https://social.anoxinon.de/@Codeberg/115033796075422170 Codeberg reported that at least one AI crawler was capable of bypassing Anubis],:
<blockquote>…we can confirm that at least Huawei networks now send the challenge responses and they actually do seem to take a few seconds to actually compute the answers… we assume that AI crawlers leveled up their computing power to emulate more of real browser behaviour </blockquote>
* [[Cloudflare]] has a feature called [https://developers.cloudflare.com/bots/additional-configurations/block-ai-bots/ Block AI Bots] which you can use to block AI bots.
* [[fail2ban]] bans logins from IP addresses that show signs of malicious activity

== Proposed Tools ==
* [https://blog.cloudflare.com/introducing-pay-per-crawl/ Introducing pay per crawl: Enabling content owners to charge AI crawlers for access]
* [https://rslstandard.org RSL: Really Simple Licensing] ''RSL is an open standard that lets publishers define machine-readable licensing terms for their content, including attribution, pay per crawl, and pay per inference compensation.''

== See Also ==
* [[large language model]]
* [[robots_txt|robots.txt]]
* [https://darkvisitors.com/agents Dark Visitors keeps a list of robot user agents]. This includes AI bots which are listed in categories like "AI Agent", "AI Assistant", "AI Data Scrapers" and more general bots like "Archivers" and link preview "Fetchers".
* [[common crawl]] is intended to share site data with crawlers so they would avoid inflicting onerous web traffic

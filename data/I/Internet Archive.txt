https://indieweb.org/Internet_Archive

__TOC__
{{stub}}

The '''<dfn>[http://archive.org Internet Archive]</dfn>''' is a non-profit organization that is building a digital library, including [[archival copy]] of much of the public web.

== How to ==
===Upload an Archive===

The Internet Archive wants to create a library of publicly available files. If you have legal rights to share they will host your content. Create an account and upload your files.

When you upload files you make a page each item. An item can contain multiple files. A concert, for example, would be one item with each song in a file.

To "hotlink" to the files, to embed a podcast for example, you need to use the following http://www.archive.org/download/[IDENTIFIER]/[FILENAME] instead of https://archive.org/details/[IDENTIFIER]/[FILENAME] 

To upload files to an existing page you need to edit the item. [https://help.archive.org/hc/en-us/articles/360018139431-How-to-delete-or-add-files-to-an-existing-item- Directions for editing items]
=== Trigger an Archive ===
NOTE: As of some time around 2020-08 this no longer works, and archive.org returns an error that says "You need to be logged in to use Save Page Now."

==== Updated API ====
There is a new API documented in [https://docs.google.com/document/d/1Nsv52MvSjbLb2PCpHlat0gkzw0EvtSgpKHu4mk0MnrA/edit?usp=sharing a Google Doc]

<blockquote>Capture request
SPN2 runs on https://web.archive.org/save which requires authentication using two alternative methods:
S3 API Keys (highly preferable). Get your account’s keys at https://archive.org/account/s3.php Use HTTP Header "authorization: LOW $accesskey:$secret" in your requests.
Cookies: Get logged-in-sig and logged-in-user from your browser when you log in to https://archive.org and add them to your SPN2 HTTP requests. Cookies are not desirable because they tend to expire after a few days so you would need to login again to archive.org to get new cookies.

There is a limit of 7 concurrent save sessions per user.

To capture a web page via the API, you can use an HTTP POST or GET request as follows:
<pre><nowiki>curl -X POST -H "Accept: application/json"  -H “Authorization: LOW myaccesskey:mysecret” -d'url=http://brewster.kahle.org/' https://web.archive.org/save
or
curl -X GET -H "Accept: application/json" --cookie "logged-in-sig=AAAAAAAAAA;logged-in-user=user1%40archive.org;" https://web.archive.org/save/http://brewster.kahle.org/
</nowiki></pre>
</blockquote>
The method described below is supposed to call through to the new API and enqueue it, but it may be slower - the current quoted backlog is 671 minutes

==== Previous API ====

You can tell archive.org to crawl and archive a specific URL immediately.

<code style="display:block;padding:1em"><nowiki>$ curl -I -H "Accept: application/json" https://web.archive.org/save/{url to archive} | grep Content-Location</nowiki></code>

and you'll get a response like:

<samp><nowiki>Content-Location: /web/20160715203015/http://indieweb.org</nowiki></samp>

(We have wiki entries for [[curl -I|the <code>-I</code> option]] and [[curl -H|the <code>-H</code> option]] to <code>curl</code>.)

The response includes the path to the archived page on web.archive.org. Append this path to <kbd><nowiki>https://web.archive.org</nowiki></kbd> to build the final URL for the archived page.

==== Trigger Archive in PHP ====
PHP snippet to call the <code>curl_exec()</code> function with appropriate options/params to trigger an archive:

<pre>
$options = 
array(CURLOPT_URL => ('https://web.archive.org/save/' . $url_to_save),
      CURLOPT_HEADER => true,
      CURLOPT_RETURNTRANSFER => true,
      CURLOPT_HTTPHEADER => array('Accept: application/json'),
      CURLOPT_USERAGENT => "YOUR_CMS_NAME_HERE");
$ch = curl_init();
curl_setopt_array($ch, $options);
$response = curl_exec($ch);
$info = curl_getinfo($ch);
curl_close($ch);
</pre>

You can then check <code>$info['http_code']</code> for a numeric [[HTTP]] return code to see if there was an error (e.g. >= 400) and take action accordingly.

==== Trigger Archive in Python (with requests) ====

This method requires the 'requests' Python library.
<pre>
pip install requests
</pre>

<pre>
import requests

# fire and forget archive.org call
try:
    verify = requests.get(
        '%s%s' % ('https://web.archive.org/save/', target),
        allow_redirects=False,
        timeout=30,
    )
except:
    pass
</pre>



==== Trigger Archive in Ruby ====

This is a Ruby method that triggers archiving by the Internet Archive for a given URL. It returns the URL that you can visit to see the archived page. It uses the <a href="https://github.com/rest-client/rest-client" title="Homepage of the REST Client Ruby gem">rest-client Ruby gem</a> to make a GET request.

<pre>
require 'rest-client'

def web_archive(url)
  archive_request_response = RestClient.get("https://web.archive.org/save/#{url}")
  "https://web.archive.org" + archive_request_response.headers[:content_location]
end
</pre>

==== Trigger Archive in Browser ====
You can manually prepend <code><nowiki>https://web.archive.org/save/</nowiki></code> to a URL to save it on-demand. You can also set up a bookmarklet to archive the current page: [https://gregorlove.com/2019/04/here-is-a-javascript-bookmarklet/]

<pre>javascript:var w=window.open('https://web.archive.org/save/'+location.href,'', 'scrollbars=1,status=0,resizable=1,location=0,toolbar=0');</pre>

=== Known ===
{{new}} There is a [[Known]] plugin to auto-archive your posts and edits to your posts, as well as pages that you bookmark:
* https://www.marcus-povey.co.uk/2017/02/02/archive-org-wayback-machine-support-for-known/
* source: https://github.com/mapkyca/KnownWaybackMachine

Limitation(?)
* Appears to NOT archive the links in your posts, except for [[bookmark]] posts.
** SHOULD: Archive all pages you link to, e.g. all pages that you (even attempt to e.g. do discovery on to) send Webmentions to.
** Github issue: https://github.com/mapkyca/KnownWaybackMachine/issues/1 FIXED

=== WordPress ===
There is a useful little plugin [https://wordpress.org/plugins/post-archival/ Post Archival in the Internet Archive] which will not only archive the user's post, but will also archive all the links within the post.

=== Micro.blog ===
Micro.blog has a setting (off by default) to send new blog posts to the Internet Archive. It does not currently archive other links found in the blog post.
* https://www.manton.org/2019/02/28/automatically-save-to.html

== IndieWeb Examples ==
=== Jeremy Keith ===
{{adactio}} has been pinging web.archive.org/save to archive pages that adactio.com posts link to since 2016-09-26
=== Aaron Parecki ===
{{aaronpk}} has been pinging web.archive.org/save with every URL that a Webmention is sent to since 2016-09-26
=== Tantek ===
{{t}} implemented (2016-11-13) pinging web.archive.org/save with every URL in a link/reply-to and has been doing it from tantek.com [http://tantek.com/2016/320/t3/auto-archive-pages-link-reply since 2016-11-15].
=== Chris Aldrich ===
{{chrisaldrich}} implemented (2017-01-07) pinging the archive with URLs of both his own posts as well as links within posts using [https://wordpress.org/plugins/post-archival/ Post Archival in the Internet Archive].
=== [[svgur]] ===
{{kevinmarks}} implemented pinging the archive with URLs of the SVG display posts, and thus indirectly the SVGs themselves
=== [[mention-tech]] ===
{{kevinmarks}} implemented [http://known.kevinmarks.com/2017/day-2-saving-webmentioned-urls-to-archiveorg-100daysofindieweb (2017-01-24)] pinging the archive with both the source and target URLs of the webmention so that they get preserved too.
=== Jonathan LaCour ===
{{cleverdevil}} implemented on 4/04 (HAH!) in 2018 using the Known plugin.

== Requests ==
* [[Telegraph]] support - https://github.com/aaronpk/Telegraph/issues/14 - should support auto-archiving for any sent Webmention

== Downtime ==
While likely only the blog, [[downtime]] has happened:
* 2019-04-23:

[[File:2019-04-23-internet-archive-blog-down.png]]

And attempting to archive that page failed!

[[File:2019-04-23-ia-not-archive-ia-blog.png]]

== See Also ==
* [[archival copy]]
* [[indiearchive]]
* [[archival_copy#Link_Archiver_on_Twitter|Link Archiver on Twitter]]
* ...
* 2018-11-28 [https://gizmodo.com/when-the-internet-archive-forgets-1830462131 When the Internet Archive Forgets]
* Outage: https://twitter.com/internetarchive/status/1143378990826004480
** "http://archive.org is down right now due to an unexpected outage. we are working to get it back up as soon as possible." [https://archive.org @internetarchive] June 25, 2019
* https://archive.org/details/@indieweb
* Post about the save page changes https://blog.archive.org/2019/10/23/the-wayback-machines-save-page-now-is-new-and-improved/

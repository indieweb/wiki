https://indieweb.org/robots_txt

{{stub}}
'''<dfn>robots.txt</dfn>''' is a file used to inform web crawlers what parts of a site should or should not be crawled.

Example command names:
* [[user-agent|User-agent]]
* [[Disallow]]
* [[Noindex]]
* [[Allow]]

== Examples ==
The following examples may be copy pasted into a plain text robots.txt file and placed at the root of your domain.

Brief example to block anything inside a particular top level directory "/wiki/":
<pre>
User-agent: *
Disallow: /wiki/
</pre>

Note that Google seems to ignore the "*" User-agent and must be specifically disallowed:
<pre>
User-agent: Googlebot
Disallow: /wiki/
</pre>

You may want to entirely block some particularly abusive bots:
<pre>
User-agent: AhrefsBot
Disallow: /
</pre>

More examples:
* http://pin13.net/robots.txt

== See Also ==
* [[robots]]
* https://www.robotstxt.org/robotstxt.html
* LOL: https://web.archive.org/web/20140702214604/https://www.google.com/killer-robots.txt
